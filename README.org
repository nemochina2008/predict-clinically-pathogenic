** 18 Aug 2016

- new data from Najmeh, with 16 numeric features.
- [[file:some.models.R]] computes single-variable and 16-variable models
  (not all pairs of two-variable models, which takes a long time with
  so many features).
- [[file:figure-some-test-error.R]] plots the test error of each model. It
  is clear that the tree and forest models are more accurate than any
  single variable model, and that they are about as accurate as
  several two-variable models, such as ctree or cforest with
  VEST3_score and CADD_phred.

[[file:figure-some-test-error.png]]

** 18 Feb 2016

Computed the test error for the best univariate thresholding
classifier using each feature. The best univariate thresholding models
are Polyphen2 and CADD, but the multivariate ctree and cforest models
definitely seem to be more accurate. 

[[file:figure-test-error.png]]

I also fit ctree and cforest models for all pairs of scores. The pair
of scores that comes closest to the 7-score model is CADD and SIFT. I
used them to create the following visualization of the predicted
probabilities of the tree and forest models (when trained in this
two-dimensional feature space).

[[file:figure-two-features.png]]

While talking over tea Simon recommended reading about related methods
- http://www.columbia.edu/~ii2135/Eigen_11_24.pdf
- http://www.pnas.org/content/111/4/1253.full.pdf

** 17 Feb 2016

First train data set from Najmeh, 1200 observations (genomic
variants/positions) x 7 scores.

Computed test error via 5-fold CV of tree and forest models, which are
definitely more accurate than a trivial majority classifier.
