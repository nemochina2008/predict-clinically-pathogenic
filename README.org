** 12 Oct 2016

[[http://cbio.mines-paristech.fr/~thocking/figure-BP-other-models/][Interactive figure with ROC curves]].

** 5 Oct 2016

[[file:BP.other.models.R]] performs a fold-fold cross-validation
experiment with four different data sets, and the new xgboost model.

[[file:figure-BP-other-models.R]] makes a figure that summarizes the
prediction accuracy of the different models in the four-fold
cross-validation experiment. It is clear that xgboost is as good as,
and sometimes better than, the single variable models, for all train
and test sets.

[[file:figure-BP-other-models-four.png]]

** 19 Aug 2016
[[
file:figure-BP-other-models.R]] makes this interactive figure [[http://bl.ocks.org/tdhock/raw/5dbfe365b3329a6155f027e141cbf803/]] and the following static figures 

[[file:figure-BP-other-models-accuracy.png]]

[[file:figure-BP-other-models-auc.png]]

These data indicate that the models trained on one data set yield
highly accurate predictions on the other data. The multi-feature model
is also just about as good as the best single-feature model
(VEST3_score). The reason why these results are different from the
previous cross-validation experiment is the treatment of NA values by
the baseline methods. Before those baseline models were just ignoring
the NA values. Now those baseline models will predict whatever label
is more frequent for the NA values in the training set. For example
this makes a big difference for the VEST3_score, because almost all
the observations with NA for VEST3_score are Pathogenic.

** 18 Aug 2016

- new data from Najmeh, with 16 numeric features.
- [[file:some.models.R]] computes single-variable and 16-variable models
  (not all pairs of two-variable models, which takes a long time with
  so many features).
- [[file:figure-some-test-error.R]] plots the test error of each model. It
  is clear that the tree and forest models are more accurate than any
  single variable model, and that they are about as accurate as
  several two-variable models, such as ctree or cforest with
  VEST3_score and CADD_phred.

[[file:figure-some-test-error.png]]

** 18 Feb 2016

Computed the test error for the best univariate thresholding
classifier using each feature. The best univariate thresholding models
are Polyphen2 and CADD, but the multivariate ctree and cforest models
definitely seem to be more accurate. 

[[file:figure-test-error.png]]

I also fit ctree and cforest models for all pairs of scores. The pair
of scores that comes closest to the 7-score model is CADD and SIFT. I
used them to create the following visualization of the predicted
probabilities of the tree and forest models (when trained in this
two-dimensional feature space).

[[file:figure-two-features.png]]

While talking over tea Simon recommended reading about related methods
- http://www.columbia.edu/~ii2135/Eigen_11_24.pdf
- http://www.pnas.org/content/111/4/1253.full.pdf

** 17 Feb 2016

First train data set from Najmeh, 1200 observations (genomic
variants/positions) x 7 scores.

Computed test error via 5-fold CV of tree and forest models, which are
definitely more accurate than a trivial majority classifier.
